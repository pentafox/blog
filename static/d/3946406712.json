{"data":{"allStrapiArticle":{"edges":[{"node":{"id":"Article_1","Title":"Something About Mobile Apps","Category":"Digital_Strategy","Image":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='267'%3e%3cpath%20d='M0%20134v133h120a564%20564%200%2000126-2c0%202%201%202%2077%202h78V0H234C68%200%2066%200%2066%202l-5%205-3%205-1%201h-3c-2-1-2-2-2-5%200-8%200-8-27-8H0v134M206%2012l-2%207a5391%205391%200%2000-37%2088V94c0-14%200-15-2-17-5-7-29-9-58-5-25%202-31%204-32%209-1%202-2%203-5%204-12%205-13%2014-4%2031l4%205c2%202%201%203-3%204-5%200-17%204-19%206-4%203-4%209-1%2012%205%204%2012%206%2029%207a597%20597%200%200074%200l-5%2014a5718%205718%200%200061-152m-15%2075l-35%2088c-5%2013-5%2014-2%2014a10267%2010267%200%2001240%2040l6%201V128l-17-2a2933%202933%200%2001-83-10l28%202c5%201%206-1%201-2l-8-1h-7l-5-1-7-1h-2v-2a4291%204291%200%200196%208h4V46h-26a1999%201999%200%2000-49-2c0-2%202-5%202-3%200%201%206%202%207%201h2l2%201h6l6-1c2-2%201-2-5-2l-5-1h-11l-2-1c1-2%2015-2%2049-1l24%201V12l-89-1h-90l-30%2076M48%2021l-5%203c-2%200-9%207-10%2010-2%204-1%208%201%208l7%202h4c2-2%206-2%208%201h2l-1-13c-1-14-1-15-6-11m177%2013l4%202c5%201%206%202%201%203l-5-1c-1-2-1-2-2%200-1%203-1%203%203%203l87%203h9l1-4%201-4-25-1a38321%2038321%200%2001-74-1m19%2024c1%201%201%201-1%201-3-1-5%200-5%201l-1%201-1%202h-2l-1%202-1%201-1%202v2l-1%202h-1c0%201%201%202%202%201l2%201-2%201c-1-2-3%202-3%205%201%203%204%204%209%204%2013-3%2021-27%208-27-3%200-3%200-1%201m-45%2042c-1%202%203%203%208%203l2%202c0%202-8%202-10%200s-2-2-2%200l-1%203%2090%208h9l1-4%201-4a2935%202935%200%2000-98-8M96%20162l-9%203-7%203-15%203-18%203c-7%200-15%203-18%206l-9%206c-2%201-2%201%202%202%206%202%2027-2%2030-5l7-1c4%200%206%200%208-2l8-6%201%203c0%202%200%202%204%202l8-2c4-2%207-2%2013-2%209-1%2031-3%2037-5%203-1%206-4%205-5a641%20641%200%2000-47-3m41%2023l-4%207-6%202-11%204c-5%202-8%204-5%204l1%201c0%201-3%201-8-1-2%200-8%205-8%208l3%203c2%201%202%201%200%202-1%200-2%200-1%201l1%202%201%201h1l1-1v-1c1%200%202-1%201-2l2-1%205%201%204%202v2l1%202%201%202%201-1%201-2%201%202c-1%201%200%202%201%202l1%201v1l2%201-4-1h-4c-2%201-2%201%201%202l6%201c2%201%203%201%202%203l2%201c1%200%202%200%201-1-2-1-1-2%202-1%202%200%203%200%203-2l-1-3v-3l2-1c0-2%204-6%207-7h3l-4-2c-2%200-4-2-5-3-3-2-4-10-2-12s8-17%208-18l-3%205m77%2065c0%202%201%202%2014%205%207%201%2011%203%2013%204%202%202%202%202%204%201%204-5%202-7-6-8l-12-3c-9-2-13-1-13%201'%20fill='%23292733'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.4933333333333334,"src":"/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/a4054/aa81e80dbc0675daadc5ce6c8eeea48a.jpg","srcSet":"/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/9e884/aa81e80dbc0675daadc5ce6c8eeea48a.jpg 112w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/87cee/aa81e80dbc0675daadc5ce6c8eeea48a.jpg 225w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/a4054/aa81e80dbc0675daadc5ce6c8eeea48a.jpg 449w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/b4fce/aa81e80dbc0675daadc5ce6c8eeea48a.jpg 674w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/1f64e/aa81e80dbc0675daadc5ce6c8eeea48a.jpg 899w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/0d976/aa81e80dbc0675daadc5ce6c8eeea48a.jpg 6016w","srcWebp":"/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/a4b3b/aa81e80dbc0675daadc5ce6c8eeea48a.webp","srcSetWebp":"/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/a17a2/aa81e80dbc0675daadc5ce6c8eeea48a.webp 112w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/8bcc4/aa81e80dbc0675daadc5ce6c8eeea48a.webp 225w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/a4b3b/aa81e80dbc0675daadc5ce6c8eeea48a.webp 449w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/88618/aa81e80dbc0675daadc5ce6c8eeea48a.webp 674w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/53789/aa81e80dbc0675daadc5ce6c8eeea48a.webp 899w,\n/static/ff6cbb8cf8ab2cdb4f1ddb96ce582985/1cae7/aa81e80dbc0675daadc5ce6c8eeea48a.webp 6016w","sizes":"(max-width: 449px) 100vw, 449px"}}},"Description":"Enterprises aim for better customer engagement, efficient business process automation and greater outreach in the market. You are one click away from reaching out to masses. Unwound your business presence gloablly with the advantage of websites and mobile apps.\n\nHowever, after a feature has either been 100 percent rolled out to our users or an experimental feature has been deemed unsuccessful, the feature flag in the code becomes obsolete. These nonfunctional feature flags represent technical debt, making it difficult for developers to work on the codebase, and can bloat our apps, requiring unnecessary operations that impact performance for the end user and potentially impact overall app reliability. \n\nRemoving this debt can be time-intensive for our engineers, preventing them from working on newer features.\n\nSeeking to automate this process, we developed Piranha, a tool that scans source code to delete code related to stale, or obsolete, feature flags, leading to a cleaner, safer, more  performant, and more maintainable code base. We run Piranha at Uber in an ongoing pipeline for our Android and iOS codebases, and have used it to remove around two thousand stale feature flags and their related code.\n\nWe believe Piranha offers great utility for organizations that use feature flags in their app deployments, and so have open sourced it. Currently implemented for Objective-C, Swift, and Java programs, open source contributors may want to apply Piranha to other languages or improve on its ability to perform deep code refactorings.\n\n#### Technical debt due to stale flags\nWhen a flag becomes stale, it should be disabled in the feature flag management system and all code artifacts related to the flag need to be removed from the source code, including the now-unreachable implementation of alternative versions of the feature. This ensures improved code hygiene and avoids technical debt. \n\nIn practice, developers do not always perform this simple post-cleanup process, leaving in code related to obsolete flags, causing accumulation of technical debt. The presence of code related to these unnecessary flags can affect software development across multiple dimensions. First, developers have to reason about the control flow related to these obsolete flags, as well as deal with a large swath of unreachable code in the monorepo. Second, such code might still be made executable in unexpected cases (e.g. due to a flag management backend error), reducing the overall reliability of the application. Third, effort must be spent to maintain test coverage of these unnecessary paths. Finally, the presence of dead code and tests impacts the overall build and testing time, affecting developer productivity.\n\n#### Automatically deleting code related to stale flags\nTo address the problem of technical debt due to stale feature flags, we designed and implemented Piranha, an automated source-to-source code refactoring tool, which is used to automatically generate differential revisions (in other words, diffs) to delete code corresponding to stale feature flags. Piranha takes as input the name of the flag, expected treatment behavior, and the name of the flag’s author. It analyzes the abstract syntax trees (ASTs) of the program to generate appropriate refactorings which are packaged into a diff. The diff is assigned to the author of the flag for further inspection, who can then land (commit to master) as is, or perform any additional refactorings before landing it. We also built workflows around Piranha for it to periodically remove stale code in a configurable manner. \n\n#### Feature flag example\nLet’s go over a simple example illustrating the basic usage of feature flags in the source code at Uber.\n\nInitially we define a new flag named RIDES_NEW_FEATURE amongst a list of flags in RidesExpName, and register it in the flag management system. Subsequently, we write the flag into the code using a feature flag API, isTreated, and provide the implementations of treatment/control behaviors under the if and else branches, respectively:\n```\npublic enum RidesExpName implements ExpName {\n   RIDES_NEW_FEATURE,\n   …\n}\n\nif (experiments.isTreated(RIDES_NEW_FEATURE)) {\n     // implementation for treatment (on) behavior\n} else {\n     // implementation for control (off) behavior\n}\n```\n\nTo test the code with various flag values, for each unit test, we can add an annotation to specify the value of the feature flag. Below, test_new_feature runs when the flag under consideration is in a treated state:\n```\n@Test\n@RidesExpTest(treated=RidesExpName.RIDES_NEW_FEATURE)\npublic void test_new_feature() {\n   …\n}\n```\n\nWhen ```RIDES_NEW_FEATURE``` becomes stale, all the code related to it needs to be removed from the codebase. This includes:\n\n1. The definition in RidesExpName.\n2. Its usage in the isTreated API.\n3. The annotation @RidesExpTest.\n\nAdditionally, the contents of the else-branch, implementing the now unreachable control behavior, must be deleted. We also want to delete code for any tests which involve this removed behavior.\n\nNot deleting these code artifacts can gradually increase the complexity and overall maintainability of our source code. \n\n### Automation challenges\nUnsurprisingly, there exist many difficulties in automating detection of obsolete flags and associated code removal. These range from determining whether a flag was in use to who owns the flag and down to the specifics of how its code was written. Overcoming these challenges was key to Piranha’s development.\n\n#### Flag staleness\nDetermining whether a flag is stale or not is surprisingly non-trivial. First, the flag should have been rolled out 100 percent either as treatment or as control. A flag that is not 100 percent rolled out presumably means its experiment is still in progress. Even when it is rolled out, the developer may not be ready to eliminate the flag. For example, flags may be used as kill switches or for monitoring debug information. Therefore, even when flags are completely rolled out, they still might be in use. \n\n#### Flag ownership\n During Uber’s early growth determining ownership information for stale flags became challenging. Even if we could perfectly determine flag authorship, the author in question may have moved to another team or left the organization. \n\n#### Coding style\nThe lack of any restrictions pertaining to code related to feature flags increases the complexity underlying the design of an automated tool. For example, helper functions for flag-related code cannot be easily differentiated from any other function in the code. Also, the complexities introduced by tests where developers allow manual state changes to the flag can restrict the tool in performing a comprehensive cleanup. For instance, when flag-related code is being unit tested, sometimes it is unclear whether the test can be discarded in its entirety because the functionality is removed, or specific state changes within the body of the test need to be removed so that the remaining functionality can continue to be tested. \n\n#### Building Piranha using static analysis\nGiven our shared background in program analysis, we envisioned that this problem can effectively be solved by applying static analysis to delete unnecessary code due to stale flags. \n\nWe identified three key dimensions for performing the cleanup: \n\n- Delete code that immediately surrounds the feature flag APIs.\n- Delete code that becomes unreachable due to performing the previous step. We refer to this as deep cleaning.\n- Delete tests related to feature flags.\nIn order to perform precise cleanup across all three dimensions, it would be necessary to perform reachability analysis to identify code regions that become unreachable and implement algorithms to identify tests related to testing feature flags. While this would ideally ensure complete automation where a developer simply needs to review the deletions and land the changes in master, it requires overcoming two challenges: ensuring that the underlying analysis to perform cleanup is sound and complete, and that the engineering effort required to implement and scale such analysis to processing millions of lines of code in a useful timeframe is available. \n\nSince determining reachability in a sound and complete manner is often impractical, we decided against building a complex analysis where the amount of developer intervention post-cleanup is unknown and the return on engineering investment is unclear. Instead, we chose a practical approach of designing the technique iteratively, based on the coding patterns observed in the codebase. \n\nWe observed that there are three kinds of flag APIs:\n\n- **Boolean API**s that return a boolean value and are used to determine the control path taken by the execution. \n- **Update API**s which update the feature flag value in the running system.\n- **Parameter API**s that return a non-boolean primitive value (integer, double, etc) which corresponds to an experimental value being controlled from the back end.\nOur refactoring technique parses the ASTs of the input source code to detect the presence of feature flag APIs that use the flag under consideration. For boolean APIs, we perform a simple boolean expression simplification. If the resulting value is a boolean constant, we refactor the code appropriately. For example, if the boolean API occurs as part of an if statement and simplifies to true, we refactor the code by deleting the entire >if statement, replacing it with the statement(s) inside the then clause. \n\nFor update APIs, we simply delete the corresponding statement. We do not handle parameter APIs as the engineering effort required to address them was much larger and the frequency of their occurrence in the codebase much lower. \n\nSince we observe that the boolean APIs need not always be used within a conditional guard, we designed a second pass for our refactoring. We identify assignments where the right hand side is a boolean API that Piranha has simplified to a constant and track the assignee variables. Similarly, we track wrapper methods that return a boolean API which is simplified to a constant. Subsequently, we identify uses of the assignee variables or wrapper methods in conditional guards to perform the refactoring. \n\nFinally, we handle flag annotations for tests by discarding the entire test if the flag annotation does not match the input treatment behavior. Otherwise, we simply delete the annotation for the test.\n\nIn summary, Piranha takes as input the following: the stale flag under consideration, the treatment behavior, and the owner of the flag. It analyzes the code for uses of this flag in pre-defined feature flag APIs and refactors it to delete code paths based on the treatment behavior.","user":{"username":"sriram","created_at":"22 Mar, 2020","updated_at":"22 Mar, 2020"}}}]}}}